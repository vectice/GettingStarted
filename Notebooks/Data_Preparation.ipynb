{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Before your start with this Tutorial\n",
        "\n",
        "**Tutorial Intention:** Providing an example of iteration and related step on a modeling phase for you to:\n",
        "\n",
        "*   Experience the data science lifecycle using Vectice\n",
        "*   See how simple it is to connect your notebook to Vectice\n",
        "*   Learn how to structure and log your work using Vectice\n",
        "\n",
        "**Resources needed:**\n",
        "*   Forecast Unit Sales Tutorial Project: You can find it as part of your personal workspace named after your name\n",
        "*   Vectice Webapp Documentation: \n",
        "*   Vectice API documentation: "
      ],
      "metadata": {
        "id": "oPX79IPtYc1M"
      },
      "id": "oPX79IPtYc1M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PIP install Packages"
      ],
      "metadata": {
        "id": "Sza-_p0FIVRj"
      },
      "id": "Sza-_p0FIVRj"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-dotenv gql Deprecated requests_toolbelt\n",
        "!pip install --q squarify\n",
        "!pip install --q s3fs\n",
        "!pip install --upgrade boto3\n",
        "!pip install --q plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1JgsE995DE4",
        "outputId": "51870cb5-9088-4364-c150-0eac30a74976"
      },
      "id": "f1JgsE995DE4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 202 kB 66.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.5 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "spacy 3.4.3 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "confection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --index-url https://test.pypi.org/simple/ vectice==22.4.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUUx9duv5Gir",
        "outputId": "2a2e3e27-1c3d-49f7-e946-f33dad794b69"
      },
      "id": "gUUx9duv5Gir",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vectice==22.4.7.1\n",
            "  Downloading https://test-files.pythonhosted.org/packages/39/13/1664ea8ae0eedb9d9c93587069553247520487843462a8499765b50b811d/vectice-22.4.7.1-py2.py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from vectice==22.4.7.1) (2.23.0)\n",
            "Requirement already satisfied: gql in /usr/local/lib/python3.7/dist-packages (from vectice==22.4.7.1) (3.4.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from vectice==22.4.7.1) (1.24.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/dist-packages (from vectice==22.4.7.1) (1.2.13)\n",
            "Requirement already satisfied: python-dotenv>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from vectice==22.4.7.1) (0.21.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->vectice==22.4.7.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->vectice==22.4.7.1) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->vectice==22.4.7.1) (2.10)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->vectice==22.4.7.1) (1.14.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /usr/local/lib/python3.7/dist-packages (from gql->vectice==22.4.7.1) (3.2.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from gql->vectice==22.4.7.1) (1.8.1)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from gql->vectice==22.4.7.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.2 in /usr/local/lib/python3.7/dist-packages (from graphql-core<3.3,>=3.2->gql->vectice==22.4.7.1) (4.4.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.6->gql->vectice==22.4.7.1) (6.0.2)\n",
            "Installing collected packages: vectice\n",
            "Successfully installed vectice-22.4.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHPFBM5v0NLJ"
      },
      "source": [
        "#Import libraries"
      ],
      "id": "bHPFBM5v0NLJ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.098471,
          "end_time": "2022-01-15T09:50:45.169883",
          "exception": false,
          "start_time": "2022-01-15T09:50:45.071412",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XZcbJYGm0NLK",
        "outputId": "1b17e3e5-bb50-4bb6-bdbe-8018be4129db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# importing mathematical and ds libraries\n",
        "import pandas as pd  # data science essentials\n",
        "import matplotlib.pyplot as plt  # essential graphical output\n",
        "import numpy as np   # mathematical essentials\n",
        "%matplotlib inline\n",
        "\n",
        "# import Visual libraries\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns  # enhanced graphical output\n",
        "\n",
        "#importing other libraries\n",
        "import IPython.display #this is for our data pipeline\n",
        "import logging\n",
        "import json\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# D3 modules\n",
        "from IPython.core.display import display, HTML, Javascript\n",
        "from string import Template\n",
        "import datetime\n",
        "from datetime import timedelta"
      ],
      "id": "XZcbJYGm0NLK"
    },
    {
      "cell_type": "code",
      "source": [
        "#import the Vectice Library\n",
        "import vectice\n",
        "from vectice import FileDataWrapper, DatasetSourceUsage"
      ],
      "metadata": {
        "id": "qONMQE4P5g-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fb41bc-efdf-4fb5-c65e-79288a391877"
      },
      "id": "qONMQE4P5g-9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning:\n",
            "\n",
            "urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect to Vectice, Project and Phase"
      ],
      "metadata": {
        "id": "k46WDbLh5uub"
      },
      "id": "k46WDbLh5uub"
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to vectice Using the API\n",
        "retail_ws = vectice.connect(config=r\"API_token.json\")"
      ],
      "metadata": {
        "id": "IUteQEfj5QuD"
      },
      "id": "IUteQEfj5QuD",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to the project\n",
        "retail_project = retail_ws.project(project=\"Tutorial Project: Forecast in store unit sales\")"
      ],
      "metadata": {
        "id": "MxTpn7yl53Bi"
      },
      "id": "MxTpn7yl53Bi",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the phase for Data Preparation \n",
        "DP = retail_project.phase(\"Data Preparation\")"
      ],
      "metadata": {
        "id": "vxsT_Fa98t2W"
      },
      "id": "vxsT_Fa98t2W",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the currently active iteration\n",
        "iter = DP.iteration"
      ],
      "metadata": {
        "id": "UOfeZCVTHvKu"
      },
      "id": "UOfeZCVTHvKu",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTOovB4Y0NLL"
      },
      "source": [
        "## Select Data "
      ],
      "id": "VTOovB4Y0NLL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Select Data step\n",
        "step = iter.step(\"Select Data\")"
      ],
      "metadata": {
        "id": "wOeozox59BUa"
      },
      "id": "wOeozox59BUa",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoW5Ppdv0NLM"
      },
      "outputs": [],
      "source": [
        "items = pd.read_csv(\"items.csv\")\n",
        "holiday_events = pd.read_csv(\"holidays_events.csv\", parse_dates=['date'])\n",
        "stores = pd.read_csv(\"stores.csv\")\n",
        "oil = pd.read_csv(\"oil.csv\", parse_dates=['date'])\n",
        "transactions = pd.read_csv(\"transactions.csv\", parse_dates=['date'])\n",
        "df = pd.read_csv(\"train_trimmed.csv\")"
      ],
      "id": "AoW5Ppdv0NLM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the FileDataWrapper to create the DataSource for the datasets\n",
        "items_file_wrapped = FileDataWrapper(path=\"items.csv\", name=\"Items origin\")\n",
        "holiday_file_wrapped = FileDataWrapper(path=\"holidays_events.csv\", name=\"Holiday origin\")\n",
        "stores_file_wrapped = FileDataWrapper(path=\"stores.csv\", name=\"Stores origin\")\n",
        "oil_file_wrapped = FileDataWrapper(path=\"oil.csv\", name=\"Oil origin\")\n",
        "transactions_file_wrapped = FileDataWrapper(path=\"transactions.csv\", name=\"Transactions origin\")\n",
        "df_file_wrapped = FileDataWrapper(path=\"train_trimmed.csv\", name=\"Training origin\")"
      ],
      "metadata": {
        "id": "mAL78-UJ-D31"
      },
      "id": "mAL78-UJ-D31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retail_project.origin_dataset = items_file_wrapped\n",
        "retail_project.origin_dataset = holiday_file_wrapped\n",
        "retail_project.origin_dataset = oil_file_wrapped\n",
        "retail_project.origin_dataset = transactions_file_wrapped\n",
        "retail_project.origin_dataset = df_file_wrapped"
      ],
      "metadata": {
        "id": "f-8s8Q0fD7hk"
      },
      "id": "f-8s8Q0fD7hk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step.close(message=\"We selected the main dataset: Corporation Favorita Dataset\")"
      ],
      "metadata": {
        "id": "V4Y6XJl0Q1fG"
      },
      "id": "V4Y6XJl0Q1fG",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean Data"
      ],
      "metadata": {
        "id": "XvWTfINn_Iyp"
      },
      "id": "XvWTfINn_Iyp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Clean Data step\n",
        "step = iter.step(\"Clean data\")"
      ],
      "metadata": {
        "id": "rAIFvpN1TMq9"
      },
      "execution_count": 13,
      "outputs": [],
      "id": "rAIFvpN1TMq9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffxyGarQ0NLO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "6c268be8-6c5b-4f67-db79-f11befdea617"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-82eb4f28128b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#preview of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "df.head() #preview of the dataset"
      ],
      "id": "ffxyGarQ0NLO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoXj3UPk0NLP"
      },
      "outputs": [],
      "source": [
        "#add missing date\n",
        "min_oil_date = min(train.date)\n",
        "max_oil_date = max(train.date)\n",
        "\n",
        "calendar = []\n",
        "\n",
        "d1 = min_oil_date\n",
        "d2 = max_oil_date\n",
        "\n",
        "delta = d2 - d1         # timedelta\n",
        "\n",
        "for i in range(delta.days + 1):\n",
        "    calendar.append(datetime.date.strftime(d1 + timedelta(days=i), '%Y-%m-%d'))\n",
        "\n",
        "calendar = pd.DataFrame({'date':calendar})\n",
        "\n",
        "oil = calendar.merge(oil, left_on='date', right_on='date', how='left')"
      ],
      "id": "CoXj3UPk0NLP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-x10k8x0NLQ"
      },
      "outputs": [],
      "source": [
        "#Check how many NA\n",
        "print(oil.isnull().sum(), '\\n')\n",
        "\n",
        "#Type\n",
        "print('Type : ', '\\n', oil.dtypes)\n",
        "\n",
        "#Print the 3 first line\n",
        "oil.head(5)"
      ],
      "id": "m-x10k8x0NLQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0WvoyxH0NLR"
      },
      "outputs": [],
      "source": [
        "#Check index to apply the formula\n",
        "na_index_oil = oil[oil['dcoilwtico'].isnull() == True].index.values\n",
        "\n",
        "#Define the index to use to apply the formala\n",
        "na_index_oil_plus = na_index_oil.copy()\n",
        "na_index_oil_minus = np.maximum(0, na_index_oil-1)\n",
        "\n",
        "for i in range(len(na_index_oil)):\n",
        "    k = 1\n",
        "    while (na_index_oil[min(i+k,len(na_index_oil)-1)] == na_index_oil[i]+k):\n",
        "        k += 1\n",
        "    na_index_oil_plus[i] = min(len(oil)-1, na_index_oil_plus[i] + k )\n",
        "\n",
        "#Apply the formula\n",
        "for i in range(len(na_index_oil)):\n",
        "    if (na_index_oil[i] == 0):\n",
        "        oil.loc[na_index_oil[i], 'dcoilwtico'] = oil.loc[na_index_oil_plus[i], 'dcoilwtico']\n",
        "    elif (na_index_oil[i] == len(oil)):\n",
        "        oil.loc[na_index_oil[i], 'dcoilwtico'] = oil.loc[na_index_oil_minus[i], 'dcoilwtico']\n",
        "    else:\n",
        "        oil.loc[na_index_oil[i], 'dcoilwtico'] = (oil.loc[na_index_oil_plus[i], 'dcoilwtico'] + oil.loc[na_index_oil_minus[i], 'dcoilwtico'])/ 2    "
      ],
      "id": "Z0WvoyxH0NLR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJcKkCU40NLS"
      },
      "outputs": [],
      "source": [
        "#Make sure the dates are all the same format\n",
        "holiday_events['date'] = pd.to_datetime(holiday_events['date'], format=\"%Y-%m-%d\")\n",
        "oil['date'] = pd.to_datetime(oil['date'], format=\"%Y-%m-%d\")\n",
        "holiday_events.dtypes"
      ],
      "id": "TJcKkCU40NLS"
    },
    {
      "cell_type": "code",
      "source": [
        "#remove id for the dataset\n",
        "df = df.drop('id', axis = 1)\n",
        "\n",
        "#create the clean dataset\n",
        "df.to_csv(\"Corpo_fav_cleaned.csv\")"
      ],
      "metadata": {
        "id": "WdBR4aam_-Xp"
      },
      "id": "WdBR4aam_-Xp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrap dataset to export metadata to Vectice to access it from the webapp\n",
        "clean_file_wrapped = FileDataWrapper(path=\"Corpo_fav_cleaned.csv\", name=\"Corpo_fav_cleaned\")\n",
        "retail_project.origin_dataset = clean_file_wrapped"
      ],
      "metadata": {
        "id": "dIjvUVYSHU40"
      },
      "id": "dIjvUVYSHU40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close step, mark it as completed in the webapp and publish message\n",
        "step.close(message=\"I replaced NaN and missing values by their mean value. I changed boolean variable into Integers. I Renamed columns to be consistent. I dropped IDs as they were not making sense for our analysis. I transformed dates into date format as some were delaying weird results\")"
      ],
      "metadata": {
        "id": "d8Dqb4NtTTRE"
      },
      "execution_count": 14,
      "outputs": [],
      "id": "d8Dqb4NtTTRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construct Data"
      ],
      "metadata": {
        "id": "mpfRvuGpDa9O"
      },
      "id": "mpfRvuGpDa9O"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Construct data step\n",
        "step = iter.step(\"Construct Data\")"
      ],
      "metadata": {
        "id": "tvLsZ3WzT7xY"
      },
      "execution_count": 15,
      "outputs": [],
      "id": "tvLsZ3WzT7xY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.167783,
          "end_time": "2022-01-15T09:54:03.562802",
          "exception": false,
          "start_time": "2022-01-15T09:54:03.395019",
          "status": "completed"
        },
        "tags": [],
        "id": "qVv2Oq7u0NLd"
      },
      "source": [
        "**Here we analyze the data and select the features for our model to be trained on.**"
      ],
      "id": "qVv2Oq7u0NLd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.165965,
          "end_time": "2022-01-15T09:54:03.894763",
          "exception": false,
          "start_time": "2022-01-15T09:54:03.728798",
          "status": "completed"
        },
        "tags": [],
        "id": "Xw7eNxg-0NLd"
      },
      "source": [
        "\n",
        "* **Train**: id, date, store_nbr, item_nbr, unit_scale, on_promotion\n",
        "* **Items**: item_nbr, family, class, perishable\n",
        "* **Holidays_events**: date, type, locale, locale_name, description, transferred\n",
        "* **Stores**: store_nbr, city, state, type, cluster\n",
        "* **Oil**: date, dcoilwtico\n",
        "* **Transactions**: date, store_nbr, transactions"
      ],
      "id": "Xw7eNxg-0NLd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.168723,
          "end_time": "2022-01-15T09:54:04.231620",
          "exception": false,
          "start_time": "2022-01-15T09:54:04.062897",
          "status": "completed"
        },
        "tags": [],
        "id": "9qEg7swL0NLd"
      },
      "source": [
        "**Selected features as inputs to the model**\n",
        "\n",
        "* date, holiday.type, holidaye.locale, holiday.locale_name, holiday_transfered, \n",
        "* store_nbr, store.city, store.state, store.type, store.cluster, transactions, \n",
        "* item_nbr, item.family, item.class, on_promotion, perishable, dcoilwtico.\n",
        "\n",
        "**Selected features as outputs of the model**\n",
        "* transactions per store, unit_sales per item"
      ],
      "id": "9qEg7swL0NLd"
    },
    {
      "cell_type": "code",
      "source": [
        "#Close step, mark it as completed in the webapp and publish message\n",
        "step.close(message=\"For our model output, we selected unit sales. For our model input we selected: date, holiday.type, holidaye.locale, holiday.locale_name, holiday_transfered, store_nbr, store.city, store.state, store.type, store.cluster, transactions, item_nbr, item.family, item.class, on_promotion, perishable, dcoilwtico.\")"
      ],
      "metadata": {
        "id": "Sckpx01rAvBU"
      },
      "id": "Sckpx01rAvBU",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integrate Data"
      ],
      "metadata": {
        "id": "yAuIRBZXAYAR"
      },
      "id": "yAuIRBZXAYAR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Integrate data step\n",
        "step = iter.step(\"Integrate Data\")"
      ],
      "metadata": {
        "id": "ZYsFI8nZ_394"
      },
      "id": "ZYsFI8nZ_394",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk67bVFd0NLT"
      },
      "outputs": [],
      "source": [
        "#Merge train\n",
        "df = df.merge(stores, left_on='store_nbr', right_on='store_nbr', how='left')\n",
        "df = df.merge(items, left_on='item_nbr', right_on='item_nbr', how='left')\n",
        "df = df.merge(holiday_events, left_on='date', right_on='date', how='left')\n",
        "df = df.merge(oil, left_on='date', right_on='date', how='left')\n",
        "\n",
        "#drop column that are not needed\n",
        "df = df.drop(['description', 'locale_name'], axis = 1)"
      ],
      "id": "Qk67bVFd0NLT"
    },
    {
      "cell_type": "code",
      "source": [
        "#create the ready for modeling dataset\n",
        "df.to_csv(\"r4modeling.csv\")\n",
        "\n",
        "#save that new dataset to Vectice\n",
        "r4m_file_wrapped = FileDataWrapper(path=\"r4modeling.csv\", name=\"Ready4modeling\")\n",
        "retail_project.origin_dataset = r4m_file_wrapped"
      ],
      "metadata": {
        "id": "T2o4dCjPIj1l"
      },
      "id": "T2o4dCjPIj1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close step, mark it as completed in the webapp and publish message\n",
        "step.close(message=\"I merged the stores, items, holiday events and oil dataset to my main dataset to bring additional informations\")"
      ],
      "metadata": {
        "id": "zgMMFCPhAcNl"
      },
      "id": "zgMMFCPhAcNl",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.167221,
          "end_time": "2022-01-15T09:54:04.567001",
          "exception": false,
          "start_time": "2022-01-15T09:54:04.399780",
          "status": "completed"
        },
        "tags": [],
        "id": "UeNXNMfO0NLe"
      },
      "source": [
        "# Format Data"
      ],
      "id": "UeNXNMfO0NLe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Format data step\n",
        "step = iter.step(\"Format Data\")"
      ],
      "metadata": {
        "id": "pnHU8zeyAp1d"
      },
      "id": "pnHU8zeyAp1d",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": 0.279687,
          "end_time": "2022-01-15T09:54:05.347688",
          "exception": false,
          "start_time": "2022-01-15T09:54:05.068001",
          "status": "completed"
        },
        "tags": [],
        "id": "ndetMdJi0NLe"
      },
      "outputs": [],
      "source": [
        "# create the datapipeline to clean data and automate transformation\n",
        "import datetime as dt\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class prepare_data(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        print(\"prepare_data -> init\")\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        train_stores = X[0].merge(X[1], right_on = 'store_nbr', left_on='store_nbr')\n",
        "        train_stores_oil = train_stores.merge(X[2], right_on='date', left_on='date')\n",
        "        train_stores_oil_items = train_stores_oil.merge(X[3], right_on = 'item_nbr', left_on = 'item_nbr')\n",
        "        train_stores_oil_items_transactions = train_stores_oil_items.merge(X[4], right_on = ['date', 'store_nbr'], left_on = ['date', 'store_nbr'])\n",
        "        train_stores_oil_items_transactions_hol = train_stores_oil_items_transactions.merge(X[5], right_on = 'date', left_on = 'date')\n",
        "        \n",
        "        data_df = train_stores_oil_items_transactions_hol.copy(deep = True)\n",
        "        \n",
        "        # Fill the empty values\n",
        "        data_df['onpromotion'] = data_df['onpromotion'].fillna(0)\n",
        "        # change the bool to int\n",
        "        data_df['onpromotion'] = data_df['onpromotion'].astype(int)\n",
        "        data_df['transferred'] = data_df['transferred'].astype(int)\n",
        "\n",
        "        # change the names\n",
        "        data_df.rename(columns={'type_x': 'st_type', 'type_y': 'hol_type'}, inplace=True)\n",
        "\n",
        "        # drop the id\n",
        "        data_df.drop(['id'], axis=1, inplace=True)\n",
        "        \n",
        "        print(data_df.head())\n",
        "        \n",
        "        # handle date\n",
        "        data_df['date'] = pd.to_datetime(data_df['date'])\n",
        "        data_df['date'] = data_df['date'].map(dt.datetime.toordinal)\n",
        "                \n",
        "        return data_df"
      ],
      "id": "ndetMdJi0NLe"
    },
    {
      "cell_type": "code",
      "source": [
        "#Close step, mark it as completed in the webapp and publish message\n",
        "step.close(message=\"I created a data pipeline to be able to reproduce and streamline the data preparation for future data. The process would include inputing nulls in numerical attributes, applying standard scalar and encoding categorical data.\")"
      ],
      "metadata": {
        "id": "4BPaQhLlU_Vk"
      },
      "execution_count": 20,
      "outputs": [],
      "id": "4BPaQhLlU_Vk"
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m94",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4527.062431,
      "end_time": "2022-01-15T11:06:02.218444",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-01-15T09:50:35.156013",
      "version": "2.3.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "f3244003ce06b8d4815ef5829ab9017a925cc64cacb0a80d02b1f6e20420f2b3"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XvWTfINn_Iyp",
        "mpfRvuGpDa9O",
        "LLE0ynMP0NLd",
        "UeNXNMfO0NLe",
        "q8C8jaoYanUT"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}